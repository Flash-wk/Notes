\section{V : Algorithms II - Sort}
\label{chap:algos2}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
\frametitle{Algorithms : Sorting}
\begin{columns}[T]

\begin{column}{0.45\textwidth}
\lstinputlisting[style=basicc,linerange={5-32},numbers=none]{../Code/ChapV/bubble.c}
\outputlisting{../Code/ChapV/bubble.autoout}
\end{column}

\pause
\begin{column}{0.45\textwidth}
\begin{itemize}[<+->]
\item Bubblesort has complexity $O(n^2)$, therefore very inefficient.
\item If an algorithm uses comparison keys to decide the correct order
then the theoretical lower bound on complexity is $O(n \log n )$. From wiki:
\pause
\begin{center}
\includegraphics[width=0.6\textwidth]{../Images/1280px-Comparison_computational_complexity.png}
\end{center}
\end{itemize}
\end{column}

\end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
\frametitle{Algorithms : Merge Sort}
\begin{columns}[T]

\begin{column}{0.35\textwidth}
\begin{itemize}[<+->]
\item Transposition (Bubblesort)
\item Insertion Sort (Lab Work)
\item Priority Queue (Selection sort, Heap sort)
\item Divide \& Conquer (Merge \& Quick sorts)
\item Address Calculation (Proxmap)
\end{itemize}
\end{column}

\pause
\begin{column}{0.55\textwidth}
\begin{itemize}[<+->]
\item Merge sort is divide-and-conquer in that you
divide the array into two halves, mergesort each half and
then merge the two halves into order.
\end{itemize}
\pause
\lstinputlisting[style=basicc,linerange={1-26}]{../Code/ChapV/merges.c}
\end{column}

\end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
\frametitle{Merge Sort II}
\begin{columns}[T]

\begin{column}{0.50\textwidth}
\lstinputlisting[style=basicc,linerange={28-60},numbers=none]{../Code/ChapV/merges.c}
\end{column}

\pause
\begin{column}{0.40\textwidth}
\begin{itemize}[<+->]
\item Quicksort is also divide-and-conquer.
\item Choose some value in the array as the {\it pivot} key.
\item This key is used to divide the array into two partitions.
The left partition contains keys
$\leq$ pivot key, the right partition contains keys $>$ pivot.
\item Once again, the sort is then applied recursively.
\end{itemize}
\end{column}

\end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
\frametitle{Algorithms : Quicksort}
\begin{columns}[T]

\begin{column}{0.45\textwidth}
\lstinputlisting[style=basicc,linerange={1-31}]{../Code/ChapV/quicks.c}
\end{column}

\pause
\begin{column}{0.45\textwidth}
\lstinputlisting[style=basicc,linerange={33-52},numbers=none]{../Code/ChapV/quicks.c}
\end{column}

\end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
\frametitle{qsort()}
\begin{columns}[T]

\begin{column}{0.45\textwidth}
\begin{itemize}[<+->]
\item Theoretically both methods have a complexity $O(n \log n)$
\item Quicksort is preferred because it requires less memory and is generally faster.
\item Quicksort can go badly wrong if the pivot key chosen is either the maximum or minimum value in the array.
\item Quicksort is so loved by programmers that a library version of it exists in ANSI C.
\item If you need an off-the-shelf sort, this is often a good option.
\end{itemize}
\end{column}

\pause
\begin{column}{0.45\textwidth}
\lstinputlisting[style=basicc]{../Code/ChapV/qsort.c}
\end{column}

\end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
\frametitle{Algorithms : The Radix Sort}
\begin{columns}[T]

\begin{column}{0.45\textwidth}
\begin{itemize}[<+->]
\item The radix sort is also know as the bin sort, a name derived from its origin as a technique used on (now obsolete) card sorters.
\item For integer data, repeated passes of radix sort focus on the right digit (the units), then the second digit (the tens)
and so on.
\item Strings could be sorted in a similar manner.
\end{itemize}
\end{column}

\pause
\begin{column}{0.45\textwidth}
459 254 472 534 649 239 432 654 477\\
\vspace*{1em}
{\bf 0}\\
{\bf 1}\\
{\bf 2} 472 432\\
{\bf 3}\\
{\bf 4} 254 534 654\\
{\bf 5}\\
{\bf 6}\\
{\bf 7} 477\\
{\bf 8}\\
{\bf 9} 459 649 239\\
\vspace*{1em}
Read out the new list:

472 432 254 534 654 477 459 649 239
\end{column}

\end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
\frametitle{Radix Sort II}
\begin{columns}[T]

\begin{column}{0.45\textwidth}
472 432 254 534 654 477 459 649 239\\
\vspace*{1em}
{\bf 0}\\
{\bf 1}\\
{\bf 2}\\
{\bf 3} 432 534 239\\
{\bf 4} 649\\
{\bf 5} 254 654 459\\
{\bf 6}\\
{\bf 7} 472 477\\
{\bf 8}\\
{\bf 9}\\
\vspace*{1em}
432 534 239 649 254 654 459 472 477
\end{column}

\pause
\begin{column}{0.45\textwidth}
432 534 239 649 254 654 459 472 477\\
\vspace*{1em}
{\bf 0}\\
{\bf 1}\\
{\bf 2} 239 254\\
{\bf 3}\\
{\bf 4} 432 459 472 477\\
{\bf 5} 534\\
{\bf 6} 649 654\\
{\bf 7}\\
{\bf 8}\\
{\bf 9}\\
\vspace*{1em}
239 254 432 459 472 477 534 649 654
\end{column}

\end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
\frametitle{Radix Sort Discussion and gprof}

\begin{columns}[T]

\begin{column}{0.45\textwidth}
\begin{itemize}[<+->]
\item This has a theoretical complexity of $O(n)$.
\item It is difficult to write an all-purpose radix sort - you need a different one for doubles, integers, strings etc.
\item $O(n)$ simply means that the number of operations can be bounded by $k.n$, for some constant $k$.
\item With the radix sort, $k$ is often very large.
\item For many lists this may be less efficient than more traditional $O(n \log n)$ algorithms.
\end{itemize}
\end{column}

\begin{column}{0.45\textwidth}
\begin{itemize}[<+->]
\item Sometimes you'll want to profile your code.
\item Compile with the \verb^-pg^ flag.
\item Executing your code produces a \verb^gmon.out^ file.
\item Now: \verb^gprof ./executable gmon.out^ shows the function-call profile of your code.
\end{itemize}
\end{column}

\end{columns}
\end{frame}
